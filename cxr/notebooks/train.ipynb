{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522412fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mlflow\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, average_precision_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset, Image as HFImage, ClassLabel, Sequence\n",
    "import cv2\n",
    "import timm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecabe2",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821743f1",
   "metadata": {},
   "source": [
    "# Class Blueprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b805057",
   "metadata": {},
   "source": [
    "## Dataset related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyHE:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Convert to grayscale and ensure 2D if not already\n",
    "        if len(img_np.shape) == 3: # Image has channels\n",
    "            if img_np.shape[2] == 4: # RGBA to GRAY\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2GRAY)\n",
    "            elif img_np.shape[2] == 3: # RGB to GRAY\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "            elif img_np.shape[2] == 1: # Grayscale (H,W,1) to 2D (H,W)\n",
    "                img_np = img_np.squeeze(axis=2) \n",
    "            else:\n",
    "                # Handle other unexpected number of channels\n",
    "                raise ValueError(f\"Unsupported number of channels: {img_np.shape[2]} for image of shape {img_np.shape}\")\n",
    "        elif len(img_np.shape) != 2: # Not 2D (grayscale) or 3D (color/grayscale with 1 channel)\n",
    "             raise ValueError(f\"Unsupported image shape dimensions: {img_np.shape}\")\n",
    "\n",
    "        # Ensure the image is 8-bit unsigned integer type. \n",
    "        # np.array(PIL Image) typically returns uint8, but good to be explicit.\n",
    "        if img_np.dtype != np.uint8:\n",
    "            img_np = img_np.astype(np.uint8)\n",
    "\n",
    "        eq_img = cv2.equalizeHist(img_np)\n",
    "\n",
    "        eq_img_rgb = cv2.cvtColor(eq_img, cv2.COLOR_GRAY2RGB)\n",
    "        return Image.fromarray(eq_img_rgb)\n",
    "\n",
    "class ApplyCLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Convert to grayscale and ensure 2D if not already\n",
    "        if len(img_np.shape) == 3: # Image has channels\n",
    "            if img_np.shape[2] == 4: # RGBA to GRAY\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGBA2GRAY)\n",
    "            elif img_np.shape[2] == 3: # RGB to GRAY\n",
    "                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "            elif img_np.shape[2] == 1: # Grayscale (H,W,1) to 2D (H,W)\n",
    "                img_np = img_np.squeeze(axis=2)\n",
    "            else:\n",
    "                # Handle other unexpected number of channels\n",
    "                raise ValueError(f\"Unsupported number of channels: {img_np.shape[2]} for image of shape {img_np.shape}\")\n",
    "        elif len(img_np.shape) != 2: # Not 2D (grayscale) or 3D (color/grayscale with 1 channel)\n",
    "             raise ValueError(f\"Unsupported image shape dimensions: {img_np.shape}\")\n",
    "\n",
    "        # Ensure the image is 8-bit unsigned integer type.\n",
    "        if img_np.dtype != np.uint8:\n",
    "            img_np = img_np.astype(np.uint8)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        clahe_img = clahe.apply(img_np)\n",
    "\n",
    "        clahe_img_rgb = cv2.cvtColor(clahe_img, cv2.COLOR_GRAY2RGB)\n",
    "        return Image.fromarray(clahe_img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIHChestXrayDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None, num_classes=15):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hf_dataset (Dataset): The loaded Hugging Face dataset split (e.g., 'train').\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Get the item from the Hugging Face dataset\n",
    "        item = self.hf_dataset[idx]\n",
    "        image = item['image']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        labels = item['labels']\n",
    "        \n",
    "        # Initialize a zero vector for 15 classes\n",
    "        label_tensor = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for label_idx in labels:\n",
    "            label_tensor[label_idx] = 1.0\n",
    "\n",
    "        return image, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e6f8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.75, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        bce = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        p = torch.sigmoid(logits)\n",
    "        p_t = p * targets + (1 - p) * (1 - targets)\n",
    "\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "\n",
    "        focal = alpha_t * (1 - p_t).pow(self.gamma) * bce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal.sum()\n",
    "        else:\n",
    "            return focal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e8299",
   "metadata": {},
   "source": [
    "## Model related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af8826b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet50(weights=\"DEFAULT\")\n",
    "        self.num_classes = num_classes\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        in_feat = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_feat, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5dafe478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextVit(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        # Load the model with its original head\n",
    "        self.model = timm.create_model(\n",
    "            \"nextvit_base.bd_in1k\",\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # Freeze the backbone\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Get the number of input features from the model's head\n",
    "        in_feat = self.model.head.fc.in_features\n",
    "        \n",
    "        # Create a new trainable head\n",
    "        self.model.head.fc = nn.Linear(in_feat, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51f8f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINOv3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.model = torch.hub.load(\"facebookresearch/dinov3\",\n",
    "                                    \"dinov3_vitb16\",\n",
    "                                    source=\"github\", \n",
    "                                    weights=\"../checkpoints/dinov3_vitb16_pretrain.pth\")\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.head = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cff5a",
   "metadata": {},
   "source": [
    "# Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1db1ad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashsy\\miniforge3\\envs\\dino_venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# baseline transformations\n",
    "training_tfms = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    ApplyCLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "validation_tfms = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    ApplyCLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Sohaibsoussi/NIH-Chest-X-ray-dataset-small\")\n",
    "class_names = dataset['train'].features['labels'].feature.names\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "training_ds = NIHChestXrayDataset(dataset['train'], transform=training_tfms)\n",
    "val_ds = NIHChestXrayDataset(dataset['validation'], transform=validation_tfms)\n",
    "test_ds = NIHChestXrayDataset(dataset['test'], transform=validation_tfms)\n",
    "\n",
    "train_loader = DataLoader(training_ds, batch_size=training_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=training_params['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=training_params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b6677",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c10100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer(optimizer_name, parameters, learning_rate):\n",
    "    \"\"\"Returns the optimizer based on the given name.\"\"\"\n",
    "    if optimizer_name == \"Adam\":\n",
    "        return optim.Adam(parameters, lr=learning_rate)\n",
    "    elif optimizer_name == \"AdamW\":\n",
    "        return optim.AdamW(parameters, lr=learning_rate, weight_decay=training_params[\"weight_decay\"])\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        return optim.SGD(parameters, lr=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "def initialize_model(model_name):\n",
    "    \"\"\"Returns the model based on the given name.\"\"\"\n",
    "    if model_name.lower() == \"resnet\":\n",
    "        model = ResNet50().to(config['device'])\n",
    "    elif model_name.lower() == \"nextvit\":\n",
    "        model = NextVit().to(config['device'])\n",
    "    elif model_name.lower() == 'dinov3':\n",
    "        model = DINOv3().to(config['device'])\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not recognized. Use 'resnet', 'nextvit or 'dinov3'\")\n",
    "    return model\n",
    "\n",
    "def initialize_criterion(loss_fn='bce', pos_weight=None):\n",
    "    \"\"\"Returns the loss function based on the given name.\"\"\"\n",
    "    if loss_fn == 'bce':\n",
    "        if pos_weight:\n",
    "            return nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        return nn.BCEWithLogitsLoss()\n",
    "    elif loss_fn == 'focal loss':\n",
    "        return FocalLoss()\n",
    "    else:\n",
    "        raise ValueError(f\"Use only 'bce' with or without pos_weight or 'focal loss' only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Current LR: {lr:.5f}\")\n",
    "    \n",
    "    for feat, labels in tqdm(train_loader, desc='Training'):\n",
    "        feat, labels = feat.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(feat)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    return float(np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        losses = []\n",
    "\n",
    "        for features, labels in tqdm(val_loader, desc='Validation'):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        y_prob = np.concatenate(all_probs, axis=0)\n",
    "        y_true = np.concatenate(all_labels, axis=0)\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "        pr, rc, f1, _ = precision_recall_fscore_support(\n",
    "            y_true.ravel(), y_pred.ravel(), average='micro', zero_division=0\n",
    "        )\n",
    "        pr_auc = average_precision_score(y_true, y_prob, average='micro')\n",
    "        roc_auc = roc_auc_score(y_true, y_prob, average='micro')\n",
    "        avg_loss = np.mean(losses)\n",
    "    return losses, avg_loss, {\"precision\": pr, \"recall\": rc, \"f1\": f1, \"pr_auc\": pr_auc, \"roc_auc\": roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30ce33d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(metrics_in_epochs, gap):\n",
    "    best_metric_idx = np.argmin(metrics_in_epochs)\n",
    "    if (len(metrics_in_epochs) - best_metric_idx >= gap):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_modelcv(train_loader, val_loader, model, criterion, optimizer, num_epochs, device, scheduler=None):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_avg_loss = []\n",
    "    val_measure = []\n",
    "    lowest_loss = float('inf')\n",
    "    best_metrics = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        train_loss = train_epoch(train_loader, model, criterion, optimizer, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss, avg_loss, metrics = evaluate(val_loader, model, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(\"Performance ROC-AUC: \", metrics['roc_auc'])\n",
    "        val_avg_loss.append(avg_loss)\n",
    "        val_measure.append(metrics['roc_auc'])\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "        # save best model\n",
    "        if avg_loss < lowest_loss:\n",
    "            best_weights = model.state_dict()\n",
    "            lowest_loss = avg_loss\n",
    "            best_metrics = metrics\n",
    "            best_epoch = epoch\n",
    "            print(f\"Current Best is epoch {best_epoch} with loss: {lowest_loss}\")\n",
    "\n",
    "        if early_stopping(val_avg_loss, 10):\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    return best_weights, best_metrics, best_epoch, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ae60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_loss(train_loss, val_loss, save=False, show=False):\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(val_loss, label='val loss')\n",
    "    plt.title(f\"Train and Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    if save:\n",
    "        plot_path = f\"loss_curve.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        return plot_path\n",
    "    else:\n",
    "        plt.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ade7f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment('CXR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2271300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['resnet', 'nextvit', 'dinov3']\n",
    "\n",
    "for model_name in model_list:\n",
    "    run_name = f\"{model_name}_AdamW_{training_params['learning_rate']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        mlflow.log_params(training_params)\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "\n",
    "        model = initialize_model(model_name)\n",
    "        criterion = initialize_criterion('bce')\n",
    "        optimizer = initialize_optimizer('AdamW', model.parameters(), training_params['learning_rate'])\n",
    "\n",
    "        best_weights, best_metrics, _, train_losses, val_losses = train_modelcv(\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            num_epochs=training_params['num_epochs'],\n",
    "            device=config['device']\n",
    "        )\n",
    "        mlflow.log_metrics(best_metrics)\n",
    "\n",
    "        # saving loss plots as local file to log as artifact, then remove local file\n",
    "        plot_path = plot_train_val_loss(train_losses, val_losses, save=True, show=False)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        os.remove(plot_path)\n",
    "\n",
    "        # run inference\n",
    "        print(\"=\" * 10)\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"===RUNNING INFERENCE ON TEST SET===\")\n",
    "\n",
    "        model.load_state_dict(best_weights)\n",
    "        _, _, test_metrics = evaluate(test_loader, model, criterion, device=config['device'])\n",
    "        mlflow.log_metrics({\n",
    "            'test_precision': test_metrics['precision'],\n",
    "            'test_recall': test_metrics['recall'],\n",
    "            'test_f1': test_metrics['f1'],\n",
    "            'test_prauc': test_metrics['pr_auc'],\n",
    "            'test_rocauc': test_metrics['roc_auc']\n",
    "        })\n",
    "\n",
    "        print(\"Inference results:\\n\", test_metrics)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
